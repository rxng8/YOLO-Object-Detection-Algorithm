{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_coco_ds.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo Object detection training\n",
        "* Download normalizaed coco dataset here: https://drive.google.com/file/d/14xELdFQwyfnbFUvdnoCu5WpXCso4xc2-/view?usp=sharing\n",
        "* After downloading, upload to this colab file!\n",
        "* Or you can use the code below to download using the file id: 14xELdFQwyfnbFUvdnoCu5WpXCso4xc2-"
      ],
      "metadata": {
        "id": "vQAw3551hypI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/*"
      ],
      "metadata": {
        "id": "104R6frenM9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/a/62568654\n",
        "!gdown --id 14xELdFQwyfnbFUvdnoCu5WpXCso4xc2-"
      ],
      "metadata": {
        "id": "6klu1rTEraS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!mkdir train\n",
        "!unzip /content/train2014.zip -d /content/train/\n",
        "!rm -rf /content/train2014.zip\n",
        "\n",
        "!wget http://images.cocodataset.org/zips/val2014.zip\n",
        "!mkdir val\n",
        "!unzip /content/val2014.zip -d /content/val/\n",
        "!rm -rf /content/val2014.zip"
      ],
      "metadata": {
        "id": "J4bJJQ6ftWz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clone library\n",
        "!git clone https://github.com/rxng8/YOLO-Object-Detection-Algorithm"
      ],
      "metadata": {
        "id": "hliuM5aDjTlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move file\n",
        "import shutil\n",
        "import os\n",
        "source = '/content/YOLO-Object-Detection-Algorithm'\n",
        "dest = '/content/'\n",
        "files = os.listdir(source)\n",
        "for f in files:\n",
        "  shutil.move(os.path.join(source, f), os.path.join(dest, f))\n",
        "!rm -rf '/content/YOLO-Object-Detection-Algorithm'"
      ],
      "metadata": {
        "id": "ujQxUjBckLS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library\n",
        "# !pip uninstall tensorflow\n",
        "# !pip install tensorflow-gpu==2.6.0\n",
        "!pip install matplotlib\n",
        "!pip install opencv-python\n",
        "!pip install tqdm\n",
        "# !pip install keras==2.6.0"
      ],
      "metadata": {
        "id": "m11ToU_NDS_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import sys\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "import json\n",
        "import csv\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.config.experimental.list_physical_devices('CPU'))\n",
        "print(tf.config.experimental.list_physical_devices('GPU'))\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import ImageDraw, ImageFont, Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "\n",
        "import tqdm\n",
        "\n",
        "from yolo.const import *\n",
        "from yolo.utils import draw_boxes, dynamic_iou, iou, show_img, preprocess_image, show_img_with_bbox\n",
        "from yolo.model import SimpleModel, \\\n",
        "  SimpleModel2, SimpleYolo, SimpleYolo2, testSimpleYolo, \\\n",
        "  SimpleYolo3, SimpleYolo4, make_yolov3_model\n",
        "from yolo.loss import yolo_loss, simple_mse_loss, yolo_loss_2, yolo_loss_3\n",
        "\n",
        "dataset_root = \"/content/\"\n",
        "train_image_folder = os.path.join(dataset_root, \"train/train2014\")\n",
        "test_image_folder = os.path.join(dataset_root, \"val/val2014\")"
      ],
      "metadata": {
        "id": "q29RuarOjfA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QJEF8lwkHoZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_pile_path = \"/content/dump.npy\"\n",
        "with open(data_pile_path, \"rb\") as f:\n",
        "    [classes, \\\n",
        "    class_to_id, \\\n",
        "    id_to_class, \\\n",
        "    train_data, \\\n",
        "    id_to_train_image_metadata, \\\n",
        "    test_data, \\\n",
        "    id_to_test_image_metadata] = np.load(f, allow_pickle=True)\n",
        "\n",
        "    n_class = len(classes)\n",
        "    train_data_size = len(list(train_data))\n",
        "    test_data_size = len(list(test_data))"
      ],
      "metadata": {
        "id": "cwoiQMzDpK9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_gen():\n",
        "  # [(image_id, [{bbox: list, category: str}]]\n",
        "  item_list = list(train_data.items())\n",
        "  pointer = 0\n",
        "  while True:\n",
        "    if pointer >= len(item_list):\n",
        "      pointer = 0\n",
        "    try:\n",
        "      ### Perform generator here\n",
        "      image_id, item_data = item_list[pointer]\n",
        "      # print(id_to_train_image_metadata[image_id])\n",
        "      \n",
        "      image_name = id_to_train_image_metadata[image_id][\"file_name\"]\n",
        "      image_path = os.path.join(train_image_folder, image_name)\n",
        "      original_img = np.asarray(Image.open(image_path))\n",
        "      original_width = id_to_train_image_metadata[image_id][\"width\"]\n",
        "      original_height = id_to_train_image_metadata[image_id][\"height\"]\n",
        "      preprocessed_img = preprocess_image(original_img, image_size=example_image_size)\n",
        "      # show_img(preprocessed_img)\n",
        "\n",
        "      label = np.zeros(\n",
        "        shape=(n_cell_y, n_cell_x, n_class + 5),\n",
        "        dtype=float\n",
        "      )\n",
        "\n",
        "      for box_data in item_data:\n",
        "        original_x, original_y, original_box_width, original_box_height = box_data[\"bbox\"]\n",
        "        _class = box_data[\"category\"]\n",
        "        _class_id = class_to_id[_class]\n",
        "\n",
        "        # Compute regarding to the currnet image. All positions range [0, 1]\n",
        "        x = float(original_x) / original_width\n",
        "        y = float(original_y) / original_height\n",
        "        box_width = float(original_box_width) / original_width\n",
        "        box_height = float(original_box_height) / original_height\n",
        "        center_x = x + box_width / 2.0\n",
        "        center_y = y + box_height / 2.0\n",
        "        # print(f\"x: {x}, y: {y}, box_width: {box_width}, box_height: {box_height}, center_x: {center_x}, center_y: {center_y}\")\n",
        "\n",
        "        # compute the coordinates center with regard to the current cell\n",
        "        xth_cell = int(center_x * n_cell_x)\n",
        "        yth_cell = int(center_y * n_cell_y)\n",
        "        cell_center_x = center_x * n_cell_x - xth_cell\n",
        "        cell_center_y = center_y * n_cell_y - yth_cell\n",
        "        cell_box_width = box_width * n_cell_x\n",
        "        cell_box_height = box_height * n_cell_y\n",
        "\n",
        "        if label[yth_cell, xth_cell, n_class + 4] == 0:\n",
        "          label[yth_cell, xth_cell, _class_id] = 1.0\n",
        "          label[yth_cell, xth_cell, n_class: n_class + 4] = cell_center_x, cell_center_y, cell_box_width, cell_box_height\n",
        "          label[yth_cell, xth_cell, n_class + 4] = 1.0\n",
        "        # boxed = draw_boxes(preprocessed_img, [[x, y, box_width, box_height]])\n",
        "        # print(f\"class: {_class}\")\n",
        "        # show_img(boxed)\n",
        "\n",
        "      yield {\n",
        "        \"input\": preprocessed_img,\n",
        "        \"output\": tf.convert_to_tensor(label)\n",
        "      }\n",
        "\n",
        "      ### End of generator performance\n",
        "      pointer += 1\n",
        "    except:\n",
        "      pointer += 1\n",
        "      continue\n",
        "\n",
        "def test_gen():\n",
        "  # [(image_id, [{bbox: list, category: str}]]\n",
        "  item_list = list(test_data.items())\n",
        "  pointer = 0\n",
        "  while True:\n",
        "    if pointer >= len(item_list):\n",
        "      pointer = 0\n",
        "    try:\n",
        "      ### Perform generator here\n",
        "      image_id, item_data = item_list[pointer]\n",
        "      image_name = id_to_test_image_metadata[image_id][\"file_name\"]\n",
        "      image_path = os.path.join(test_image_folder, image_name)\n",
        "      original_img = np.asarray(Image.open(image_path))\n",
        "      original_width = id_to_test_image_metadata[image_id][\"width\"]\n",
        "      original_height = id_to_test_image_metadata[image_id][\"height\"]\n",
        "      preprocessed_img = preprocess_image(original_img, image_size=example_image_size)\n",
        "      label = np.zeros(\n",
        "        shape=(n_cell_y, n_cell_x, n_class + 5),\n",
        "        dtype=float\n",
        "      )\n",
        "      for box_data in item_data:\n",
        "        original_x, original_y, original_box_width, original_box_height = box_data[\"bbox\"]\n",
        "        _class = box_data[\"category\"]\n",
        "        _class_id = class_to_id[_class]\n",
        "        # Compute regarding to the currnet image. All positions range [0, 1]\n",
        "        x = float(original_x) / original_width\n",
        "        y = float(original_y) / original_height\n",
        "        box_width = float(original_box_width) / original_width\n",
        "        box_height = float(original_box_height) / original_height\n",
        "        center_x = x + box_width / 2.0\n",
        "        center_y = y + box_height / 2.0\n",
        "        # compute the coordinates center with regard to the current cell\n",
        "        xth_cell = int(center_x * n_cell_x)\n",
        "        yth_cell = int(center_y * n_cell_y)\n",
        "        cell_center_x = center_x * n_cell_x - xth_cell\n",
        "        cell_center_y = center_y * n_cell_y - yth_cell\n",
        "        cell_box_width = box_width * n_cell_x\n",
        "        cell_box_height = box_height * n_cell_y\n",
        "        if label[yth_cell, xth_cell, n_class + 4] == 0:\n",
        "          label[yth_cell, xth_cell, _class_id] = 1.0\n",
        "          label[yth_cell, xth_cell, n_class: n_class + 4] = cell_center_x, cell_center_y, cell_box_width, cell_box_height\n",
        "          label[yth_cell, xth_cell, n_class + 4] = 1.0\n",
        "      yield {\n",
        "        \"input\": preprocessed_img,\n",
        "        \"output\": tf.convert_to_tensor(label)\n",
        "      }\n",
        "      ### End of generator performance\n",
        "      pointer += 1\n",
        "    except:\n",
        "      pointer += 1\n",
        "      continue"
      ],
      "metadata": {
        "id": "OqtAsebNpr5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(train_gen, output_signature={\n",
        "  \"input\": tf.TensorSpec(shape=(*example_image_size, n_channels), dtype=tf.float32),\n",
        "  \"output\": tf.TensorSpec(shape=(n_cell_y, n_cell_x, n_class + 5), dtype=tf.float32)\n",
        "})\n",
        "print(train_dataset.element_spec)\n",
        "train_batch_dataset = train_dataset.batch(batch_size=BATCH_SIZE)\n",
        "train_batch_iter = iter(train_batch_dataset)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(test_gen, output_signature={\n",
        "  \"input\": tf.TensorSpec(shape=(*example_image_size, n_channels), dtype=tf.float32),\n",
        "  \"output\": tf.TensorSpec(shape=(n_cell_y, n_cell_x, n_class + 5), dtype=tf.float32)\n",
        "})\n",
        "test_dataset_iter = iter(test_dataset)\n",
        "test_batch_dataset = train_dataset.batch(batch_size=BATCH_SIZE)\n",
        "test_batch_iter = iter(test_batch_dataset)\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "7XnGfM7tqYgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model: tf.keras.Model = make_yolov3_model()\n",
        "model.summary()\n",
        "with tf.device(\"/CPU:0\"):\n",
        "  test_logits = tf.random.normal((BATCH_SIZE, *example_image_size, n_channels), mean=0.5, stddev=0.3)\n",
        "  test_pred = model(test_logits, training=False)\n",
        "  print(test_pred.shape)"
      ],
      "metadata": {
        "id": "8Ln4aXFaqaoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(batch_x, batch_label, model, loss_function, optimizer, debug=False):\n",
        "  with tf.device(\"/GPU:0\"):\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(batch_x, training=True)\n",
        "      loss, [loss_xy, loss_wh, loss_conf, loss_class] = loss_function(batch_label, logits)\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "  if debug:\n",
        "    return logits, loss, [loss_xy, loss_wh, loss_conf, loss_class]\n",
        "  return loss, [loss_xy, loss_wh, loss_conf, loss_class]\n",
        "\n",
        "def train(model, \n",
        "        training_batch_iter, \n",
        "        test_batch_iter, \n",
        "        optimizer, \n",
        "        loss_function,\n",
        "        epochs=1, \n",
        "        steps_per_epoch=20, \n",
        "        valid_step=5,\n",
        "        history_path=None,\n",
        "        weights_path=None):\n",
        "  \n",
        "  if not os.path.exists(training_history_path):\n",
        "    epochs_val_loss = np.array([])\n",
        "    epochs_loss = np.array([])\n",
        "    history = [epochs_loss, epochs_val_loss]\n",
        "  else:\n",
        "    with open(training_history_path, \"rb\") as f:\n",
        "      history = np.load(f, allow_pickle=True)\n",
        "\n",
        "  epochs_loss, epochs_val_loss = history\n",
        "  epochs_loss = epochs_loss.tolist()\n",
        "  epochs_val_loss = epochs_val_loss.tolist()\n",
        "\n",
        "  if os.path.exists(model_weights_path + \".index\"):\n",
        "    try:\n",
        "      model.load_weights(model_weights_path)\n",
        "      print(\"Model weights loaded!\")\n",
        "    except:\n",
        "      print(\"Cannot load weights\")\n",
        "\n",
        "  # https://philipplies.medium.com/progress-bar-and-status-logging-in-python-with-tqdm-35ce29b908f5\n",
        "  # outer_tqdm = tqdm(total=epochs, desc='Epoch', position=0)\n",
        "  loss_logging = tqdm.tqdm(total=0, bar_format='{desc}', position=1)\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # https://towardsdatascience.com/training-models-with-a-progress-a-bar-2b664de3e13e\n",
        "    # https://www.geeksforgeeks.org/python-how-to-make-a-terminal-progress-bar-using-tqdm/\n",
        "    with tqdm.tqdm(total=steps_per_epoch, desc=f\"Epoch {epoch + 1}\", position=0, ncols=100, ascii =\".>\") as inner_tqdm:\n",
        "      with tf.device(\"/CPU:0\"):\n",
        "        for step_pointer in range(steps_per_epoch):\n",
        "          batch = next(training_batch_iter)\n",
        "          batch_x = batch[\"input\"]\n",
        "          batch_label = batch[\"output\"]\n",
        "          loss, [loss_xy, loss_wh, loss_conf, loss_class] = train_step(\n",
        "            batch_x, batch_label, \n",
        "            model, loss_function, optimizer)\n",
        "\n",
        "          # Log?\n",
        "          desc = f\"Epoch {epoch + 1} - Step {step_pointer + 1} - Loss: {loss}\"\n",
        "          # loss_logging.set_description_str(desc)\n",
        "          # print()\n",
        "\n",
        "          losses.append((loss, [loss_xy, loss_wh, loss_conf, loss_class]))\n",
        "\n",
        "          if (step_pointer + 1) % valid_step == 0:\n",
        "            # desc = f\"Training loss (for one batch) at step {step_pointer + 1}: {float(loss)}\"\n",
        "            # print(desc)\n",
        "            # loss_logging.set_description_str(desc)\n",
        "\n",
        "            # perform validation\n",
        "            val_batch = next(test_batch_iter)\n",
        "            logits = model(val_batch[\"input\"], training=False)\n",
        "            val_loss, [val_loss_xy, val_loss_wh, val_loss_conf, val_loss_class] = loss_function(val_batch[\"output\"], logits)\n",
        "            val_losses.append((val_loss, [val_loss_xy, val_loss_wh, val_loss_conf, val_loss_class]))\n",
        "            # print(f\"Validation loss: {val_loss}\\n-----------------\")\n",
        "\n",
        "          inner_tqdm.set_postfix_str(f\"Loss: {loss}\")\n",
        "          inner_tqdm.update(1)\n",
        "\n",
        "    epochs_loss.append(losses)\n",
        "    epochs_val_loss.append(val_losses)\n",
        "\n",
        "    # Save history and model\n",
        "    if history_path != None:\n",
        "      np.save(history_path, [epochs_loss, epochs_val_loss])\n",
        "    \n",
        "    if weights_path != None:\n",
        "      model.save_weights(weights_path)\n",
        "\n",
        "    # outer_tqdm.update(1)\n",
        "\n",
        "  # return history\n",
        "  return [epochs_loss, epochs_val_loss]\n"
      ],
      "metadata": {
        "id": "H23eVS8aqc6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history_path = \"/content/training_history/history9.npy\"\n",
        "model_weights_path = \"/content/weights/checkpoint10\"\n",
        "\n",
        "history = train(\n",
        "  model,\n",
        "  train_batch_iter,\n",
        "  test_batch_iter,\n",
        "  optimizer,\n",
        "  yolo_loss_3,\n",
        "  epochs=1,\n",
        "  steps_per_epoch=500, # 82783 // 4\n",
        "  history_path=training_history_path,\n",
        "  weights_path=model_weights_path\n",
        ")"
      ],
      "metadata": {
        "id": "ekXY0RDcqkGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}